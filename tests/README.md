# ğŸ§ª **TESTS DEL SISTEMA NER MULTI-STRATEGY**

## ğŸ“‹ **RESUMEN**

Este directorio contiene una suite completa de tests para validar tanto el **sistema refactorizado** como el **sistema original** del NER Multi-Strategy.

## ğŸ—ï¸ **ESTRUCTURA DE TESTS**

```
tests/
â”œâ”€â”€ README.md                      # Esta documentaciÃ³n
â”œâ”€â”€ conftest.py                    # ConfiguraciÃ³n global de pytest
â”œâ”€â”€ run_tests.py                   # Script ejecutor de tests
â”œâ”€â”€ unit/                          # ğŸ”§ TESTS UNITARIOS
â”‚   â”œâ”€â”€ test_config.py             # Tests de configuraciÃ³n
â”‚   â”œâ”€â”€ test_core.py               # Tests de mÃ³dulos core
â”‚   â”œâ”€â”€ test_strategies.py         # Tests de estrategias
â”‚   â””â”€â”€ test_utils.py              # Tests de utilidades
â”œâ”€â”€ integration/                   # ğŸ”— TESTS DE INTEGRACIÃ“N
â”‚   â”œâ”€â”€ test_refactored_system.py  # Tests sistema refactorizado
â”‚   â””â”€â”€ test_original_system.py    # Tests sistema original
â”œâ”€â”€ data/                          # ğŸ“Š DATOS DE PRUEBA
â”‚   â”œâ”€â”€ test_input.jsonl           # Entrada de prueba
â”‚   â””â”€â”€ test_benchmark.jsonl       # Benchmark de prueba
â””â”€â”€ fixtures/                      # ğŸ› ï¸ FIXTURES (futuro)
```

## ğŸš€ **EJECUCIÃ“N RÃPIDA**

### **Ejecutar todos los tests**
```bash
# MÃ©todo simple
python tests/run_tests.py

# Con pytest directo
python -m pytest tests/ -v
```

### **Tests especÃ­ficos**
```bash
# Solo tests unitarios
python tests/run_tests.py --type unit

# Solo tests de integraciÃ³n
python tests/run_tests.py --type integration

# Con cobertura de cÃ³digo
python tests/run_tests.py --type coverage
```

## ğŸ”§ **TESTS UNITARIOS**

### **test_config.py**
- âœ… ValidaciÃ³n de estrategias
- âœ… ConfiguraciÃ³n de umbrales
- âœ… Settings del sistema
- âœ… ValidaciÃ³n de parÃ¡metros

### **test_core.py**
- âœ… Procesamiento de texto
- âœ… GestiÃ³n de archivos
- âœ… Cliente LLM y cachÃ©
- âœ… Chunking y normalizaciÃ³n

### **test_strategies.py**
- âœ… Estrategia regex
- âœ… Orquestador multi-estrategia
- âœ… Sistema de confianza
- âœ… Manejo de errores

### **test_utils.py**
- âœ… Parser CLI
- âœ… PuntuaciÃ³n de confianza
- âœ… Matching de entidades
- âœ… ValidaciÃ³n de argumentos

## ğŸ”— **TESTS DE INTEGRACIÃ“N**

### **test_refactored_system.py**
- âœ… Flujo completo del sistema refactorizado
- âœ… Carga y procesamiento de documentos
- âœ… Guardado de resultados
- âœ… Manejo de errores
- âœ… Modo sin benchmark

### **test_original_system.py**
- âœ… Compatibilidad del sistema original
- âœ… ValidaciÃ³n de argumentos CLI
- âœ… ComparaciÃ³n de salidas
- âœ… Manejo graceful de errores
- âœ… Compatibilidad hacia atrÃ¡s

## ğŸ“Š **DATOS DE PRUEBA**

### **test_input.jsonl**
```json
{"PMID": "test_001", "Texto": "Patient diagnosed with diabetes mellitus...", "Entidad": [...]}
{"PMID": "test_002", "Texto": "Patient presents with chest pain...", "Entidad": [...]}
```

### **test_benchmark.jsonl**
Misma estructura que el input para validaciÃ³n de mÃ©tricas.

## ğŸ› ï¸ **FIXTURES GLOBALES**

Definidas en `conftest.py`:

- **`sample_documents`**: Documentos de prueba sintÃ©ticos
- **`sample_entity_candidates`**: Lista de entidades candidatas
- **`sample_strategies`**: Estrategias de prueba simplificadas
- **`temp_jsonl_file`**: Archivo temporal para tests
- **`temp_dir`**: Directorio temporal
- **`disable_llm_calls`**: Mock para llamadas LLM
- **`sample_detection_results`**: Resultados de detecciÃ³n mock

## ğŸ¯ **TIPOS DE TESTS**

### **ğŸ”§ Tests Unitarios**
- **PropÃ³sito**: Validar mÃ³dulos individuales
- **Alcance**: Funciones y clases especÃ­ficas
- **Velocidad**: RÃ¡pidos (< 1 segundo por test)
- **Dependencias**: MÃ­nimas (mocks para LLM)

### **ğŸ”— Tests de IntegraciÃ³n**
- **PropÃ³sito**: Validar interacciÃ³n entre mÃ³dulos
- **Alcance**: Flujos completos del sistema
- **Velocidad**: Moderados (1-30 segundos por test)
- **Dependencias**: Archivos, pero sin Ollama real

### **âš¡ Tests de Performance** (futuro)
- **PropÃ³sito**: Validar rendimiento
- **Alcance**: Tiempo de procesamiento
- **Velocidad**: Lentos (minutos)
- **Dependencias**: Datos reales grandes

## ğŸ“ˆ **MÃ‰TRICAS Y COBERTURA**

### **Ejecutar con cobertura**
```bash
python tests/run_tests.py --type coverage
```

### **Ver reporte HTML**
```bash
# DespuÃ©s de ejecutar tests con cobertura
open htmlcov/index.html  # Linux/Mac
start htmlcov/index.html # Windows
```

### **Objetivos de cobertura**
- **MÃ³dulos core**: > 90%
- **MÃ³dulos config**: > 95%
- **MÃ³dulos strategies**: > 85%
- **MÃ³dulos utils**: > 90%

## ğŸš¨ **TESTING SIN OLLAMA**

Los tests estÃ¡n diseÃ±ados para **NO requerir Ollama** en funcionamiento:

- **Mocks**: Llamadas LLM son interceptadas
- **Timeouts**: Tests con timeout para evitar cuelgues
- **Graceful failures**: Manejo de errores de conexiÃ³n
- **Fallbacks**: Respuestas mock predefinidas

## ğŸ”„ **CONTINUOUS INTEGRATION**

### **Pre-commit checks**
```bash
# Validar antes de commit
python tests/run_tests.py --test-scripts
python tests/run_tests.py --validate-data
python tests/run_tests.py --type unit
```

### **Full validation**
```bash
# ValidaciÃ³n completa
python tests/run_tests.py --type all --verbose
```

## ğŸ› **DEBUGGING TESTS**

### **Ejecutar test especÃ­fico**
```bash
# Test especÃ­fico
python -m pytest tests/unit/test_config.py::TestStrategies::test_all_strategies_loaded -v

# Con debugging
python -m pytest tests/unit/test_config.py -v -s --tb=long
```

### **Ejecutar con pdb**
```bash
python -m pytest tests/unit/test_config.py --pdb
```

### **Ver salida completa**
```bash
python -m pytest tests/ -v -s --tb=short
```

## âš ï¸ **LIMITACIONES ACTUALES**

### **No se testa con Ollama real**
- **RazÃ³n**: Evitar dependencia externa
- **SoluciÃ³n**: Mocks y respuestas predefinidas
- **Futuro**: Tests opcionales con Ollama real

### **Datos de prueba sintÃ©ticos**
- **RazÃ³n**: Datos pequeÃ±os y controlados
- **SoluciÃ³n**: Casos de prueba especÃ­ficos
- **Futuro**: Tests con datasets reales

### **Sin tests de carga**
- **RazÃ³n**: Enfoque en funcionalidad
- **SoluciÃ³n**: Tests de integraciÃ³n bÃ¡sicos
- **Futuro**: Tests de performance y carga

## ğŸ¯ **MEJORES PRÃCTICAS**

### **Al escribir nuevos tests**
1. **Usar fixtures** existentes cuando sea posible
2. **Aislar dependencias** con mocks
3. **Nombres descriptivos** para tests
4. **Documentar casos edge** y por quÃ© se testean
5. **Tests independientes** (sin orden especÃ­fico)

### **Al modificar el cÃ³digo**
1. **Ejecutar tests** antes de commit
2. **Agregar tests** para nuevas funcionalidades
3. **Actualizar tests** para cambios de API
4. **Verificar cobertura** no disminuya

## ğŸš€ **FUTURAS MEJORAS**

### **Tests adicionales**
- Tests de performance con datasets grandes
- Tests de stress con muchos documentos
- Tests de compatibilidad entre versiones
- Tests de regresiÃ³n automÃ¡ticos

### **Infraestructura**
- GitHub Actions para CI/CD
- Tests automÃ¡ticos en PRs
- Reportes de cobertura automÃ¡ticos
- Tests nocturnos con datos reales

### **MÃ©tricas avanzadas**
- Tiempo de ejecuciÃ³n por mÃ³dulo
- Uso de memoria durante tests
- Cobertura de branches avanzada
- Tests de mutaciÃ³n

## ğŸ“ **SOPORTE**

Para problemas con tests:

1. **Verificar datos**: `python tests/run_tests.py --validate-data`
2. **Verificar scripts**: `python tests/run_tests.py --test-scripts`
3. **Ejecutar unitarios**: `python tests/run_tests.py --type unit -v`
4. **Ver logs completos**: `python -m pytest tests/ -v -s --tb=long`

## ğŸ‰ **CONCLUSIÃ“N**

Esta suite de tests proporciona:

- âœ… **ValidaciÃ³n completa** de ambos sistemas
- âœ… **EjecuciÃ³n rÃ¡pida** sin dependencias externas
- âœ… **Cobertura amplia** de casos de uso
- âœ… **Manejo robusto** de errores
- âœ… **Compatibilidad** hacia atrÃ¡s
- âœ… **DocumentaciÃ³n clara** para mantenimiento

Los tests aseguran que tanto el **sistema refactorizado** como el **original** funcionen correctamente y mantengan compatibilidad.
