# üß¨ Sistema NER Multi-Estrategia con Llama

## üìã Descripci√≥n

Sistema avanzado de Named Entity Recognition (NER) para entidades biom√©dicas que combina m√∫ltiples estrategias de detecci√≥n usando modelos de lenguaje local (Ollama) con `llama3.2:3b` y `qwen2.5:3b`.

## ‚ö†Ô∏è **ADVERTENCIA IMPORTANTE**

**Este sistema NO es un detector autom√°tico de entidades biom√©dicas.** 

**Funciona de manera fundamentalmente diferente al NER cl√°sico:**

- **NER Cl√°sico**: Detecta autom√°ticamente todas las enfermedades/entidades en el texto sin especificarle que entidades buscar
- **Nuestro Sistema**: Solo detecta las entidades que **espec√≠ficamente** se le indique que debe buscar en el campo "Entidad" del documento

**Es un sistema de EXTRACCI√ìN DIRIGIDA para casos de uso espec√≠ficos:**

- **Ejemplo**: Si quieres extraer pacientes que tomaron "paracetamol", pones "paracetamol" en la lista
- **Resultado**: Solo encuentra "paracetamol" si est√° en el texto, no busca otras medicinas
- **Uso ideal**: Para extraer un conjunto espec√≠fico de entidades de documentos similares

**Esta limitaci√≥n es intencional y fundamental para el dise√±o del sistema.**

## üéØ Caracter√≠sticas Principales

- **4 Estrategias Complementarias**: Diferentes configuraciones de chunking y modelos
- **Sistema de Reintentos Inteligente**: Manejo robusto de respuestas LLM
- **Puntuaci√≥n de Confianza Avanzada**: Basada en m√∫ltiples estrategias y detecci√≥n regex
- **Procesamiento Paralelo**: Ejecuci√≥n simult√°nea de estrategias
- **Gesti√≥n de Memoria Eficiente**: Procesamiento basado en archivos
- **Detecci√≥n Regex**: Baseline de alta precisi√≥n para entidades conocidas

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

1. **Python 3.8+**
2. **Ollama** instalado y ejecut√°ndose
3. **Modelos descargados**:
   ```bash
   ollama pull llama3.2:3b
   ollama pull qwen2.5:3b
   ```

### Instalaci√≥n

```bash
git clone <repository>
cd bert_vs_ollama
pip install -r requirements.txt
```

## üìÅ Estructura del Proyecto

```
bert_vs_ollama/
‚îú‚îÄ‚îÄ datasets/                    # Datasets de entrada
‚îÇ   ‚îú‚îÄ‚îÄ ncbi_develop.jsonl      # Dataset de desarrollo
‚îÇ   ‚îî‚îÄ‚îÄ ncbi_test.jsonl         # Dataset de test
‚îú‚îÄ‚îÄ scripts/                     # Scripts principales
‚îÇ   ‚îú‚îÄ‚îÄ llama_ner_multi_strategy.py  # Sistema principal
‚îÇ   ‚îú‚îÄ‚îÄ run_multi_strategy_example.py # Ejemplo de uso
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_ner_performance.py  # Evaluador
‚îú‚îÄ‚îÄ results_final/               # Resultados finales
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ SEPARACION_ARCHIVOS.md  # Gu√≠a de separaci√≥n de archivos
‚îî‚îÄ‚îÄ temp_analysis/               # An√°lisis temporales
```

## üéÆ Uso

### Separaci√≥n de Archivos

El sistema ahora separa claramente dos tipos de archivos JSONL:

1. **`--input_jsonl`**: Contiene el texto a procesar y las entidades espec√≠ficas que se deben buscar
   - Campo `Texto`: El texto biom√©dico a analizar
   - Campo `Entidad`: Lista de entidades espec√≠ficas a detectar

2. **`--benchmark_jsonl`**: Contiene los datos de referencia para evaluaci√≥n
   - Permite evaluar el rendimiento del sistema de manera independiente
   - Facilita la comparaci√≥n entre diferentes configuraciones

Esta separaci√≥n permite:
- **Entrenamiento independiente**: Usar diferentes datasets para entrenamiento y evaluaci√≥n
- **Validaci√≥n cruzada**: Probar con m√∫ltiples conjuntos de benchmark
- **An√°lisis comparativo**: Evaluar el mismo modelo con diferentes datos de test

### Ejecuci√≥n B√°sica

```bash
python scripts/llama_ner_multi_strategy.py \
    --input_jsonl ./datasets/ncbi_develop.jsonl \
    --benchmark_jsonl ./datasets/ncbi_test.jsonl \
    --out_pred results_final.jsonl \
    --strategies all
```

### Par√°metros Principales

- `--input_jsonl`: Archivo de entrada JSONL con texto y entidades a buscar
- `--benchmark_jsonl`: Archivo JSONL de benchmark para evaluaci√≥n
- `--out_pred`: Archivo de salida
- `--limit`: N√∫mero m√°ximo de documentos (0 = todos)
- `--strategies`: Estrategias a usar (`all` o nombres espec√≠ficos)
- `--confidence_threshold`: Umbral m√≠nimo de confianza (default: 0.3)

### Estrategias Disponibles

1. **llama32_max_sensitivity**: Chunks grandes (100t), m√°xima sensibilidad
2. **llama32_balanced**: Chunks medianos (60t), balanceado
3. **llama32_high_precision**: Chunks peque√±os (30t), alta precisi√≥n
4. **qwen25_diversity**: Chunks peque√±os (20t), diversidad de modelo

## üìä Evaluaci√≥n

### Evaluar Rendimiento

```bash
python scripts/evaluate_ner_performance.py \
    --predictions results_final.jsonl \
    --reference ./datasets/ncbi_develop.jsonl
```

## üìö Documentaci√≥n Adicional

- **[Separaci√≥n de Archivos](docs/SEPARACION_ARCHIVOS.md)**: Gu√≠a completa sobre la nueva funcionalidad de separaci√≥n de archivos de entrada y benchmark
- **[Metodolog√≠a Detallada](docs/METODOLOGIA_DETALLADA.md)**: Explicaci√≥n t√©cnica del sistema multi-estrategia

### M√©tricas Generadas

- **Precisi√≥n**: True Positives / (True Positives + False Positives)
- **Recall**: True Positives / (True Positives + False Negatives)
- **F1-Score**: Media arm√≥nica de precisi√≥n y recall
- **An√°lisis por Estrategia**: Rendimiento individual de cada estrategia

## üîß Configuraci√≥n Avanzada

### **Optimizaciones de Rendimiento**

> ‚ö†Ô∏è **Nota Importante**: El sistema est√° optimizado para precisi√≥n, no velocidad. Las siguientes optimizaciones pueden reducir la precisi√≥n significativamente.

#### **Reducir Estrategias**
```bash
# Solo usar estrategias m√°s r√°pidas
python scripts/llama_ner_multi_strategy.py \
    --strategies llama32_high_precision,qwen25_diversity \
    --develop_jsonl ./datasets/ncbi_test.jsonl \
    --out_pred results_fast.jsonl
```

#### **Ajustar Tama√±os de Chunk**
```python
# En llama_ner_multi_strategy.py
STRATEGY_FAST = {
    "name": "llama32_fast",
    "model": "llama3.2:3b",
    "chunk_target": 150,      # Chunks m√°s grandes = menos chunks
    "chunk_overlap": 20,      # Menos overlap = menos procesamiento
    "temperature": 0.0,       # Temperatura 0 = m√°s r√°pido
    "weight": 1.0
}
```

#### **Configuraci√≥n Ollama para Velocidad**
```python
options = {
    "temperature": 0.0,
    "num_predict": 16,        # Respuestas m√°s cortas
    "num_gpu": 1,             # Usar GPU
    "num_thread": 4,          # M√°s threads
    "repeat_penalty": 1.0,    # Sin penalizaci√≥n
    "top_k": 20               # Sampling m√°s agresivo
}
```

**Resultado**: 2-3x m√°s r√°pido, precisi√≥n ~99.0-99.5%

### Personalizar Estrategias

```python
# En llama_ner_multi_strategy.py
STRATEGY_1 = {
    "name": "custom_strategy",
    "model": "llama3.2:3b",
    "chunk_target": 80,      # Tama√±o de chunk
    "chunk_overlap": 30,     # Overlap entre chunks
    "temperature": 0.2,      # Temperatura del modelo
    "weight": 1.0           # Peso en scoring
}
```

### Umbrales de Confianza

```python
CONFIDENCE_THRESHOLDS = {
    "high": 0.9,      # 3+ estrategias
    "medium": 0.7,    # 2+ estrategias
    "low": 0.5,       # 1+ estrategias
    "min_accept": 0.3 # M√≠nimo para aceptar
}
```

## üìà Rendimiento

### Resultados en Dataset de Desarrollo

- **Precisi√≥n**: 99.3%
- **Recall**: 98.9%
- **F1-Score**: 99.1%
- **Total Entidades**: 273
- **Errores**: Solo 5 (1.8% tasa de error)

### Resultados en Dataset de Test Completo

- **Precisi√≥n**: 99.7%
- **Recall**: 99.7%
- **F1-Score**: 99.7%
- **Total Entidades**: 385
- **Documentos Procesados**: 93 de 100
- **Errores**: Solo 2 (0.5% tasa de error)

### Estrategias por Rendimiento

1. **regex**: 100% precisi√≥n (384 entidades)
2. **llama32_balanced**: 100% precisi√≥n (130 entidades)
3. **llama32_max_sensitivity**: 100% precisi√≥n (122 entidades)
4. **llama32_high_precision**: 100% precisi√≥n (123 entidades)
5. **qwen25_diversity**: 100% precisi√≥n (96 entidades)

### An√°lisis de Errores

- **Documentos con errores**: Solo 1 de 93 (PMID 9674903)
- **Tipo de errores**: Variaciones en nomenclatura biom√©dica
- **Robustez**: 99.7% de precisi√≥n en dataset completo y diverso

## ‚ö° Comparaci√≥n de Rendimiento vs BERT

### **Ventajas del Sistema Multi-Estrategia**

- **Precisi√≥n Superior**: 99.7% vs ~95-97% t√≠pico de BERT
- **Flexibilidad**: Maneja variaciones de nomenclatura biom√©dica
- **Interpretabilidad**: Explicable y auditable
- **Sin Fine-tuning**: Funciona out-of-the-box
- **Adaptabilidad**: F√°cil ajuste de estrategias

### **Desventajas (Limitaciones Conocidas)**

- **Velocidad**: Significativamente m√°s lento que BERT
- **Recursos**: Requiere m√°s RAM y potencia de c√≥mputo
- **Latencia**: Cada documento requiere m√∫ltiples llamadas a LLM
- **Escalabilidad**: No optimizado para procesamiento en lote masivo

### **Limitaci√≥n Fundamental: Especificidad de Entidades**

‚ö†Ô∏è **IMPORTANTE**: Este sistema NER tiene una limitaci√≥n fundamental que lo diferencia del NER cl√°sico:

**El sistema NO extrae autom√°ticamente cualquier enfermedad o entidad biom√©dica del texto.** En su lugar, **requiere que se especifiquen expl√≠citamente las entidades que se quieren extraer** de cada documento.

#### **Ejemplo Pr√°ctico del Caso de Uso:**

**‚ùå NO funciona as√≠ (NER cl√°sico):**
- El sistema detecta autom√°ticamente todas las enfermedades mencionadas en el texto
- Encuentra "gripe", "fiebre", "dolor de cabeza", "paracetamol", etc. sin especificaci√≥n previa

**‚úÖ Funciona as√≠ (nuestro sistema - EXTRACCI√ìN DIRIGIDA):**
- **Caso de uso**: Quieres extraer solo pacientes que tomaron "paracetamol"
- **Configuraci√≥n**: Pones "paracetamol" en la lista de entidades
- **Resultado**: Solo encuentra "paracetamol" si est√° en el texto, no busca otras medicinas
- **Ventaja**: Perfecto para extraer un conjunto espec√≠fico de entidades de documentos similares

#### **Implicaciones:**
- **No es un detector universal** de entidades biom√©dicas
- **Es un extractor dirigido** para entidades espec√≠ficas predefinidas
- **Cada documento debe tener** su lista espec√≠fica de entidades objetivo
- **Ideal para casos de uso espec√≠ficos** donde se sabe exactamente qu√© buscar
- **Perfecto para extracci√≥n sistem√°tica** de un conjunto fijo de entidades
- **No adecuado para exploraci√≥n general** o descubrimiento de nuevas entidades

### **Estimaci√≥n de Tiempos Comparativa**

| M√©trica | BERT (GPU) | NER Multi-Estrategia | Factor |
|---------|------------|----------------------|---------|
| **1 documento** | ~0.1-0.5s | ~10-30s | **20-60x m√°s lento** |
| **100 documentos** | ~10-50s | ~15-45 min | **20-60x m√°s lento** |
| **1000 documentos** | ~2-8 min | ~2.5-7.5 horas | **20-60x m√°s lento** |

**Nota**: Los tiempos var√≠an seg√∫n hardware, complejidad del texto y configuraci√≥n de estrategias.

### **Casos de Uso Recomendados**

- ‚úÖ **Extracci√≥n sistem√°tica**: Cuando quieres extraer un conjunto fijo de entidades de documentos similares
- ‚úÖ **An√°lisis dirigido**: Buscar pacientes con medicamentos espec√≠ficos, enfermedades concretas, etc.
- ‚úÖ **Validaci√≥n de hip√≥tesis**: Verificar presencia de entidades espec√≠ficas en un dataset
- ‚úÖ **Investigaci√≥n cl√≠nica**: Extraer datos espec√≠ficos para estudios m√©dicos
- ‚úÖ **Datasets peque√±os-medianos**: < 1000 documentos para an√°lisis detallado
- ‚úÖ **Entornos de desarrollo**: Prototipado y experimentaci√≥n

- ‚ùå **Producci√≥n en tiempo real**: Latencia cr√≠tica
- ‚ùå **Procesamiento masivo**: > 1000 documentos
- ‚ùå **Entornos con recursos limitados**: RAM < 8GB
- ‚ùå **Aplicaciones de usuario final**: Requieren respuesta instant√°nea
- ‚ùå **Exploraci√≥n general**: Cuando no se sabe qu√© entidades buscar
- ‚ùå **Descubrimiento autom√°tico**: Detecci√≥n de nuevas entidades no especificadas

## üêõ Soluci√≥n de Problemas

### Ollama No Responde

```bash
# Verificar estado
ollama list

# Reiniciar servicio
ollama serve
```

### Errores de Memoria

- Reducir `--limit` para procesar menos documentos
- Verificar que Ollama tenga suficiente RAM disponible
- Usar estrategias con chunks m√°s peque√±os

### Baja Precisi√≥n

- Ajustar `--confidence_threshold`
- Verificar que los modelos est√©n descargados
- Revisar logs de debug para errores espec√≠ficos

## üìö Archivos de Configuraci√≥n

### Formato de Entrada de texto a procesar(JSONL)

‚ö†Ô∏è **CR√çTICO**: El campo "Entidad" define **EXACTAMENTE** qu√© entidades se extraer√°n del texto. El sistema NO detectar√° entidades que no est√©n en esta lista.

#### **Estructura B√°sica del JSONL:**

```json
{
  "PMID": "12345",
  "Texto": "Texto del documento biom√©dico...",
  "Entidad": [
    {
      "texto": "nombre de enfermedad espec√≠fica",
      "tipo": "SpecificDisease"
    },
    {
      "texto": "otra entidad a buscar",
      "tipo": "SpecificDisease"
    }
  ]
}
```

#### **Ejemplo Pr√°ctico Completo:**

```json
{
  "PMID": "9876543",
  "Texto": "El paciente presenta s√≠ntomas de gripe con fiebre alta. Se le administr√≥ paracetamol 500mg cada 8 horas. Tambi√©n presenta dolor de cabeza y tos seca. El tratamiento incluye reposo y abundante l√≠quido.",
  "Entidad": [
    {
      "texto": "paracetamol",
      "tipo": "SpecificDisease"
    },
    {
      "texto": "gripe",
      "tipo": "SpecificDisease"
    }
  ]
}
```

#### **¬øQu√© Pasar√° con este Ejemplo?**

**‚úÖ Entidades que S√ç se detectar√°n:**
- "paracetamol" - porque est√° en la lista
- "gripe" - porque est√° en la lista

**‚ùå Entidades que NO se detectar√°n (aunque aparezcan en el texto):**
- "fiebre alta" - porque NO est√° en la lista
- "dolor de cabeza" - porque NO est√° en la lista
- "tos seca" - porque NO est√° en la lista
- "reposo" - porque NO est√° en la lista

**Resultado**: Solo extraer√°s informaci√≥n sobre pacientes que tomaron paracetamol y/o tuvieron gripe, no sobre otros s√≠ntomas o tratamientos.

#### **Reglas Importantes para el Campo "Entidad":**

1. **Entidad base**: Incluye la forma principal de la enfermedad que quieres detectar
2. **El LLM maneja variaciones**: No necesitas incluir todas las variaciones posibles. El sistema LLM detectar√° autom√°ticamente:
   - Sin√≥nimos m√©dicos
   - Abreviaturas comunes
   - Variaciones en nomenclatura
   - T√©rminos relacionados

3. **Ejemplo simplificado**: Solo necesitas incluir la entidad principal:
   ```json
   {
     "texto": "paracetamol",
     "tipo": "SpecificDisease"
   }
   ```
   
   **El sistema autom√°ticamente detectar√°:**
   - "paracetamol"
   - "acetaminof√©n" (nombre alternativo)
   - "Tylenol" (marca comercial)
   - Y otras variaciones relacionadas

**Nota**: El LLM es inteligente y encuentra variaciones autom√°ticamente. No es necesario ser exhaustivo en la lista de entidades.

#### **Ejemplo de Archivo JSONL Completo:**

```jsonl
{"PMID": "123", "Texto": "Texto del primer documento...", "Entidad": [{"texto": "enfermedad A", "tipo": "SpecificDisease"}]}
{"PMID": "124", "Texto": "Texto del segundo documento...", "Entidad": [{"texto": "enfermedad B", "tipo": "SpecificDisease"}, {"texto": "enfermedad C", "tipo": "SpecificDisease"}]}
{"PMID": "125", "Texto": "Texto del tercer documento...", "Entidad": []}
```

#### **Mejores Pr√°cticas para Preparar el JSONL:**

1. **Define entidades principales**: Incluye solo las enfermedades/entidades principales que quieres detectar
2. **Usa t√©rminos m√©dicos est√°ndar** cuando sea posible
3. **Mant√©n la lista simple**: No es necesario ser exhaustivo - el LLM es inteligente
4. **Prueba con un documento peque√±o** antes de procesar todo el dataset

#### **Herramientas Recomendadas para Preparar el JSONL:**

- **Anotadores manuales**: Para definir las entidades principales que quieres detectar
- **Scripts de preprocesamiento**: Para estandarizar el formato JSONL
- **Validaci√≥n simple**: Verificar que las entidades principales est√©n bien definidas
- **Documentaci√≥n**: Mantener una lista simple de entidades objetivo por proyecto

### Formato de Salida

```json
{
  "PMID": "12345",
  "Texto": "Texto original...",
  "Entidad": [
    {
      "texto": "entidad detectada",
      "tipo": "SpecificDisease",
      "confidence": 0.95,
      "strategies": ["regex", "llama32_balanced"]
    }
  ],
  "_multi_strategy": {
    "all_detections": {...},
    "entity_confidence": {...},
    "strategies_used": [...]
  }
}
```

## ü§ù Contribuci√≥n

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.

## üìû Soporte

Para preguntas o problemas:
- Abre un issue en GitHub
- Revisa la documentaci√≥n en `docs/`
- Consulta los logs de debug para informaci√≥n detallada

## üéØ Conclusiones y Recomendaciones

### **¬øCu√°ndo Usar Este Sistema?**

- **‚úÖ M√°xima Precisi√≥n**: Cuando la precisi√≥n > 99% es cr√≠tica
- **‚úÖ Investigaci√≥n**: Para validar y mejorar otros sistemas NER
- **‚úÖ Datasets Peque√±os**: < 5000 documentos para an√°lisis detallado
- **‚úÖ Prototipado**: Desarrollo de nuevas estrategias de NER

### **¬øCu√°ndo NO Usar Este Sistema?**

- **‚ùå Producci√≥n Masiva**: > 5000 documentos diarios
- **‚ùå Tiempo Real**: Aplicaciones que requieren < 1 segundo de respuesta
- **‚ùå Recursos Limitados**: Sistemas con < 8GB RAM
- **‚ùå Escalabilidad**: Entornos que requieren procesamiento paralelo masivo

### **Trade-off: Precisi√≥n vs Velocidad**

| Aspecto | BERT | NER Multi-Estrategia |
|---------|------|----------------------|
| **Precisi√≥n** | 95-97% | **99.7%** |
| **Velocidad** | **Muy R√°pido** | 20-60x m√°s lento |
| **Recursos** | **Bajo** | Alto |
| **Flexibilidad** | Baja | **Muy Alta** |
| **Interpretabilidad** | Baja | **Muy Alta** |

**El sistema est√° dise√±ado para ser el mejor en precisi√≥n, no en velocidad.**

---

**Desarrollado para investigaci√≥n en NER biom√©dico con modelos de lenguaje local.**
