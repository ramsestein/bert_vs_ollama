# üß¨ Sistema NER Multi-Estrategia con Llama

## üìã Descripci√≥n

Sistema avanzado de Named Entity Recognition (NER) para entidades biom√©dicas que combina m√∫ltiples estrategias de detecci√≥n usando modelos de lenguaje local (Ollama) con `llama3.2:3b` y `qwen2.5:3b`.

## ‚ö†Ô∏è **ADVERTENCIA IMPORTANTE**

**Este sistema NO es un detector autom√°tico de entidades biom√©dicas.** 

**Funciona de manera fundamentalmente diferente al NER cl√°sico:**

- **NER Cl√°sico**: Detecta autom√°ticamente todas las enfermedades/entidades en el texto sin especificarle que entidades buscar
- **Nuestro Sistema**: Solo detecta las entidades que **espec√≠ficamente** se le indique que debe buscar en el campo "Entidad" del documento

**Es un sistema de EXTRACCI√ìN DIRIGIDA para casos de uso espec√≠ficos:**

- **Ejemplo**: Si quieres extraer pacientes que tomaron "paracetamol", pones "paracetamol" en la lista
- **Resultado**: Solo encuentra "paracetamol" si est√° en el texto, no busca otras medicinas
- **Uso ideal**: Para extraer un conjunto espec√≠fico de entidades de documentos similares

**Esta limitaci√≥n es intencional y fundamental para el dise√±o del sistema.**

## üéØ Caracter√≠sticas Principales

- **4 Estrategias Complementarias**: Diferentes configuraciones de chunking y modelos
- **Sistema de Reintentos Inteligente**: Manejo robusto de respuestas LLM
- **Puntuaci√≥n de Confianza Avanzada**: Basada en m√∫ltiples estrategias y detecci√≥n regex
- **Procesamiento Paralelo**: Ejecuci√≥n simult√°nea de estrategias
- **Gesti√≥n de Memoria Eficiente**: Procesamiento basado en archivos
- **Detecci√≥n Regex**: Baseline de alta precisi√≥n para entidades conocidas

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

1. **Python 3.8+**
2. **Ollama** instalado y ejecut√°ndose
3. **Modelos descargados**:
   ```bash
   ollama pull llama3.2:3b
   ollama pull qwen2.5:3b
   ```

### Instalaci√≥n

```bash
git clone <repository>
cd bert_vs_ollama
pip install -r requirements.txt
```

## üìÅ Estructura del Proyecto

```
bert_vs_ollama/
‚îú‚îÄ‚îÄ ner_multi_strategy.py              # üöÄ SISTEMA PRINCIPAL NER (ejecutar desde aqu√≠)
‚îú‚îÄ‚îÄ old_ner_multi_strategy.py          # üîÑ Sistema original (backup)
‚îú‚îÄ‚îÄ ner_app/                           # üèóÔ∏è Arquitectura modular refactorizada
‚îú‚îÄ‚îÄ tests/                             # üß™ Suite de tests completa
‚îú‚îÄ‚îÄ datasets/                          # üìä Datasets de entrada y benchmark
‚îÇ   ‚îú‚îÄ‚îÄ ncbi_develop.jsonl            # Dataset de desarrollo (NCBI)
‚îÇ   ‚îú‚îÄ‚îÄ ncbi_test.jsonl               # Dataset de test (NCBI)
‚îÇ   ‚îú‚îÄ‚îÄ n2c2_test_input.jsonl         # Dataset de entrada n2c2 (sin chest pain)
‚îÇ   ‚îî‚îÄ‚îÄ n2c2_test.jsonl               # Dataset de benchmark n2c2 (sin chest pain)
‚îú‚îÄ‚îÄ scripts/                           # üîß Scripts auxiliares de an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_ner_performance.py    # Evaluador de m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ analyze_false_positives_clean.py # An√°lisis de falsos positivos
‚îÇ   ‚îú‚îÄ‚îÄ analyze_false_negatives_clean.py # An√°lisis de falsos negativos
‚îÇ   ‚îú‚îÄ‚îÄ run_llama_grid_n2c2.py        # Grid search Llama
‚îÇ   ‚îú‚îÄ‚îÄ run_qwen_grid_n2c2.py         # Grid search Qwen
‚îÇ   ‚îî‚îÄ‚îÄ analyze_n2c2_grid_results.py  # An√°lisis de resultados grid
‚îú‚îÄ‚îÄ docs/                             # üìö Documentaci√≥n t√©cnica
‚îÇ   ‚îú‚îÄ‚îÄ METODOLOGIA_DETALLADA.md      # Explicaci√≥n t√©cnica del sistema
‚îÇ   ‚îî‚îÄ‚îÄ OPTIMIZACION_PARAMETROS.md    # Gu√≠a de optimizaci√≥n
‚îú‚îÄ‚îÄ results_final/                    # üìà Resultados finales
‚îî‚îÄ‚îÄ temp_analysis/                    # üîç An√°lisis temporales
```

## üéÆ Uso

```bash
# ‚úÖ CORRECTO - desde el directorio ra√≠z
python ner_multi_strategy.py --help

```

### Separaci√≥n de Archivos

El sistema separa claramente dos tipos de archivos JSONL:

1. **`--input_jsonl`**: Contiene el texto a procesar y las entidades espec√≠ficas que se deben buscar
   - Campo `Texto`: El texto biom√©dico a analizar
   - Campo `Entidad`: Lista de entidades espec√≠ficas a detectar

2. **`--benchmark_jsonl`**: Contiene los datos de referencia para evaluaci√≥n
   - Permite evaluar el rendimiento del sistema de manera independiente

### Ejecuci√≥n B√°sica

```bash
python ner_multi_strategy.py \
    --input_jsonl ./datasets/dataset_input.jsonl \
    --benchmark_jsonl ./datasets/dataset_test.jsonl \
    --out_pred results_final.jsonl \
    --strategies all
```

### Par√°metros Principales

- `--input_jsonl`: Archivo de entrada JSONL con texto y entidades a buscar
- `--benchmark_jsonl`: Archivo JSONL de benchmark para evaluaci√≥n
- `--out_pred`: Archivo de salida
- `--limit`: N√∫mero m√°ximo de documentos (0 = todos)
- `--strategies`: Estrategias a usar (`all` o nombres espec√≠ficos)
- `--confidence_threshold`: Umbral m√≠nimo de confianza (default: 0.5)

### Estrategias Disponibles

1. **llama32_max_sensitivity**: Chunks grandes (100t), m√°xima sensibilidad
2. **llama32_balanced**: Chunks medianos (60t), balanceado
3. **llama32_high_precision**: Chunks peque√±os (30t), alta precisi√≥n
4. **qwen25_diversity**: Chunks peque√±os (20t), diversidad de modelo

## üîß Pipeline de Optimizaci√≥n

Hemos dise√±ado un **pipeline sistem√°tico de optimizaci√≥n** para adaptar el script a nuevos datasets:

### **1. Optimizaci√≥n de Temperatura**
```bash
# Probar diferentes temperaturas para encontrar la √≥ptima
python scripts/run_llama_grid.py --dataset n2c2_develop --limit 50
```

### **2. Optimizaci√≥n de Chunks y Overlap**
```bash
# Probar diferentes configuraciones de chunking
python scripts/run_llama_grid.py --dataset n2c2_develop --limit 50
```

### **3. Optimizaci√≥n del Umbral de Confianza**
```bash
# Probar diferentes umbrales (0.3, 0.5, 0.7, 0.9)
python ner_multi_strategy.py \
    --confidence_threshold 0.5 \
    --input_jsonl ./datasets/n2c2_test_input.jsonl \
    --benchmark_jsonl ./datasets/n2c2_test.jsonl \
    --out_pred results_test.jsonl \
    --limit 50
```

### **4. Validaci√≥n y Correcci√≥n de Benchmark**
```bash
# Analizar falsos positivos para identificar errores en anotaciones humanas
python scripts/analyze_false_positives_clean.py

# Analizar falsos negativos para verificar cobertura completa
python scripts/analyze_false_negatives_clean.py
```

### **5. Actualizaci√≥n del Script Principal**
Una vez optimizados los par√°metros, se actualiza `ner_multi_strategy.py` con:
- Temperatura √≥ptima
- Configuraci√≥n de chunks √≥ptima
- Umbral de confianza √≥ptimo

## üìä Evaluaci√≥n

### Evaluar Rendimiento

```bash
python scripts/evaluate_ner_performance.py \
    --predictions results_final.jsonl \
    --reference ./datasets/n2c2_test.jsonl
```

## **Documentos Disponibles en `docs/`**

La carpeta `docs/` contiene documentaci√≥n t√©cnica detallada del proyecto:

#### **üìã Documentos Principales**

- **[METODOLOGIA_DETALLADA.md](docs/METODOLOGIA_DETALLADA.md)**
  - **Descripci√≥n**: Explicaci√≥n t√©cnica completa del sistema NER multi-estrategia
  - **Contenido**: Arquitectura del sistema, flujo de procesamiento, estrategias implementadas
  - **Audiencia**: Desarrolladores, investigadores, usuarios t√©cnicos
  - **Uso**: Referencia para entender c√≥mo funciona internamente el sistema

- **[OPTIMIZACION_PARAMETROS.md](docs/OPTIMIZACION_PARAMETROS.md)**
  - **Descripci√≥n**: Gu√≠a completa del pipeline de optimizaci√≥n de par√°metros
  - **Contenido**: Proceso sistem√°tico para optimizar temperatura, chunks, overlap y umbral de confianza
  - **Audiencia**: Usuarios que quieren adaptar el sistema a nuevos datasets
  - **Uso**: Tutorial paso a paso para optimizaci√≥n de rendimiento

#### **üéØ C√≥mo Usar la Documentaci√≥n**

1. **Para empezar**: Lee el README principal (este archivo) para una visi√≥n general
2. **Para entender el sistema**: Consulta `METODOLOGIA_DETALLADA.md` para detalles t√©cnicos
3. **Para optimizar**: Sigue `OPTIMIZACION_PARAMETROS.md` para mejorar el rendimiento
4. **Para an√°lisis**: Revisa `AUDIT_REPORT.md` y `metrics_summary.json` para resultados
5. **Para desarrollo**: Consulta `improvement_log.md` para entender la evoluci√≥n del proyecto

#### **üìñ Estructura de la Documentaci√≥n**

```
docs/
‚îú‚îÄ‚îÄ METODOLOGIA_DETALLADA.md      # üß† Explicaci√≥n t√©cnica del sistema
‚îú‚îÄ‚îÄ OPTIMIZACION_PARAMETROS.md    # ‚öôÔ∏è Gu√≠a de optimizaci√≥n
‚îî‚îÄ‚îÄ (futuros documentos)         # üìö Documentaci√≥n adicional en desarrollo

üìÅ Ra√≠z del proyecto
‚îú‚îÄ‚îÄ README.md                     # üöÄ Documentaci√≥n principal (este archivo)
‚îú‚îÄ‚îÄ AUDIT_REPORT.md              # üìä Reporte de auditor√≠a
‚îú‚îÄ‚îÄ improvement_log.md            # üìù Registro de mejoras
‚îî‚îÄ‚îÄ metrics_summary.json          # üìà Resumen de m√©tricas
```

#### **üîß Documentaci√≥n T√©cnica Adicional**

- **C√≥digo fuente**: Todos los scripts incluyen documentaci√≥n inline detallada
- **Tests**: La carpeta `tests/` contiene ejemplos de uso y validaci√≥n
- **Scripts auxiliares**: Cada script en `scripts/` incluye documentaci√≥n de uso
- **Configuraci√≥n**: Los archivos de configuraci√≥n est√°n documentados con comentarios



## üîß Configuraci√≥n Avanzada

### **Optimizaciones de Rendimiento**

> ‚ö†Ô∏è **Nota Importante**: El sistema est√° optimizado para precisi√≥n, no velocidad. Las siguientes optimizaciones pueden reducir la precisi√≥n significativamente.


#### **Ajustar Tama√±os de Chunk**
```python
# En ner_multi_strategy.py
STRATEGY_FAST = {
    "name": "llama32_fast",
    "model": "llama3.2:3b",
    "chunk_target": 150,      # Chunks m√°s grandes = menos chunks
    "chunk_overlap": 20,      # Menos overlap = menos procesamiento
    "temperature": 0.0,       # Temperatura 0 = m√°s r√°pido
    "weight": 1.0
}
```

#### **Configuraci√≥n Ollama para Velocidad**
```python
options = {
    "temperature": 0.0,
    "num_predict": 16,        # Respuestas m√°s cortas
    "num_gpu": 1,             # Usar GPU
    "num_thread": 4,          # M√°s threads
    "repeat_penalty": 1.0,    # Sin penalizaci√≥n
    "top_k": 20               # Sampling m√°s agresivo
}
```

**Resultado**: 2-3x m√°s r√°pido, precisi√≥n ~99.0-99.5%

### Personalizar Estrategias

```python
# En ner_multi_strategy.py
STRATEGY_1 = {
    "name": "custom_strategy",
    "model": "llama3.2:3b",
    "chunk_target": 80,      # Tama√±o de chunk
    "chunk_overlap": 30,     # Overlap entre chunks
    "temperature": 0.2,      # Temperatura del modelo
    "weight": 1.0           # Peso en scoring
}
```

### Umbrales de Confianza

```python
CONFIDENCE_THRESHOLDS = {
    "high": 0.9,      # 3+ estrategias
    "medium": 0.7,    # 2+ estrategias
    "low": 0.5,       # 1+ estrategias
    "min_accept": 0.5 # M√≠nimo para aceptar (optimizado para n2c2)
}
```

## üìà Rendimiento

### M√©tricas Generadas

- **Precisi√≥n**: True Positives / (True Positives + False Positives)
- **Recall**: True Positives / (True Positives + False Negatives)
- **F1-Score**: Media arm√≥nica de precisi√≥n y recall
- **An√°lisis por Estrategia**: Rendimiento individual de cada estrategia

### **Resultados en Dataset NCBI (Test Completo)**

- **Precisi√≥n**: 99.7%
- **Recall**: 99.7%
- **F1-Score**: 99.7%
- **Total Entidades**: 385
- **Documentos Procesados**: 93 de 100
- **Errores**: Solo 2 (0.5% tasa de error)

### **Resultados en Dataset n2c2 (Test - primeros 100 documentos)**

- **Precisi√≥n**: 95.4%
- **Recall**: 100.0%
- **F1-Score**: 97.6%
- **Total Entidades Reales**: 65
- **Total Entidades en Benchmark**: 47

## **An√°lisis de Correcci√≥n de Anotaciones Humanas**

Durante la evaluaci√≥n del dataset n2c2, descubrimos que **14 entidades detectadas por la m√°quina no estaban anotadas en el benchmark**, pero **eran correctas**:

- **PMID 103**: 'orthopnea' (confianza: 1.000)
- **PMID 106**: 'monitoring' (confianza: 1.000)
- **PMID 119**: 'hypertension' (confianza: 0.800)
- **PMID 121**: 'short of breath' (confianza: 0.800)
- **PMID 127**: 'monitoring' (confianza: 1.000)
- **PMID 129**: 'angina' (confianza: 1.000)
- **PMID 136**: 'short of breath' (confianza: 0.800)
- **PMID 142**: 'hypertension' (confianza: 1.000)
- **PMID 146**: 'obesity' (confianza: 1.000)
- **PMID 153**: 'hypertension' (confianza: 1.000)
- **PMID 155**: 'monitoring' (confianza: 1.000)
- **PMID 170**: 'monitoring' (confianza: 1.000)

**Conclusi√≥n**: La m√°quina tiene raz√≥n en estos casos, demostrando la capacidad del sistema para **identificar errores en anotaciones humanas** y mejorar la calidad del benchmark.


### An√°lisis de Errores

- **Documentos con errores**: Solo 3 de 100 (PMIDs 123, 128, 16)
- **Tipo de errores**: Variaciones en nomenclatura biom√©dica
- **Robustez**: 95.4% de precisi√≥n en dataset n2c2 con anotaciones corregidas

## ‚ö° Comparaci√≥n de Rendimiento vs BERT

### **Ventajas del Sistema Multi-Estrategia**

- **Precisi√≥n Superior**: 95.4-99.7% vs ~90-95% t√≠pico de BERT
- **Flexibilidad**: Maneja variaciones de nomenclatura biom√©dica
- **Interpretabilidad**: Explicable y auditable
- **Sin Fine-tuning**: Funciona out-of-the-box
- **Adaptabilidad**: F√°cil ajuste de estrategias
- **Correcci√≥n de Anotaciones**: Identifica errores en benchmarks humanos

### **Desventajas (Limitaciones Conocidas)**

- **Velocidad**: Significativamente m√°s lento que BERT
- **Recursos**: Requiere m√°s RAM y potencia de c√≥mputo
- **Latencia**: Cada documento requiere m√∫ltiples llamadas a LLM
- **Escalabilidad**: No optimizado para procesamiento en lote masivo

### **Limitaci√≥n Fundamental: Especificidad de Entidades**

‚ö†Ô∏è **IMPORTANTE**: Este sistema NER tiene una limitaci√≥n fundamental que lo diferencia del NER cl√°sico:

**El sistema NO extrae autom√°ticamente cualquier enfermedad o entidad biom√©dica del texto.** En su lugar, **requiere que se especifiquen expl√≠citamente las entidades que se quieren extraer** de cada documento.

#### **Ejemplo Pr√°ctico del Caso de Uso:**

**‚ùå NO funciona as√≠ (NER cl√°sico):**
- El sistema detecta autom√°ticamente todas las enfermedades mencionadas en el texto
- Encuentra "gripe", "fiebre", "dolor de cabeza", "paracetamol", etc. sin especificaci√≥n previa

**‚úÖ Funciona as√≠ (nuestro sistema - EXTRACCI√ìN DIRIGIDA):**
- **Caso de uso**: Quieres extraer solo pacientes que tomaron "paracetamol"
- **Configuraci√≥n**: Pones "paracetamol" en la lista de entidades
- **Resultado**: Solo encuentra "paracetamol" si est√° en el texto, no busca otras medicinas
- **Ventaja**: Perfecto para extraer un conjunto espec√≠fico de entidades de documentos similares

#### **Implicaciones:**
- **No es un detector universal** de entidades biom√©dicas
- **Es un extractor dirigido** para entidades espec√≠ficas predefinidas
- **Cada documento debe tener** su lista espec√≠fica de entidades objetivo
- **Ideal para casos de uso espec√≠ficos** donde se sabe exactamente qu√© buscar
- **Perfecto para extracci√≥n sistem√°tica** de un conjunto fijo de entidades
- **No adecuado para exploraci√≥n general** o descubrimiento de nuevas entidades

### **Estimaci√≥n de Tiempos Comparativa**

| M√©trica | BERT (GPU) | NER Multi-Estrategia | Factor |
|---------|------------|----------------------|---------|
| **1 documento** | ~0.1-0.5s | ~10-30s | **20-60x m√°s lento** |
| **100 documentos** | ~10-50s | ~15-45 min | **20-60x m√°s lento** |
| **1000 documentos** | ~2-8 min | ~2.5-7.5 horas | **20-60x m√°s lento** |

**Nota**: Los tiempos var√≠an seg√∫n hardware, complejidad del texto y configuraci√≥n de estrategias.

### **Casos de Uso Recomendados**

- ‚úÖ **Extracci√≥n sistem√°tica**: Cuando quieres extraer un conjunto fijo de entidades de documentos similares
- ‚úÖ **An√°lisis dirigido**: Buscar pacientes con medicamentos espec√≠ficos, enfermedades concretas, etc.
- ‚úÖ **Validaci√≥n de hip√≥tesis**: Verificar presencia de entidades espec√≠ficas en un dataset
- ‚úÖ **Investigaci√≥n cl√≠nica**: Extraer datos espec√≠ficos para estudios m√©dicos
- ‚úÖ **Datasets peque√±os-medianos**: < 1000 documentos para an√°lisis detallado
- ‚úÖ **Entornos de desarrollo**: Prototipado y experimentaci√≥n
- ‚úÖ **Correcci√≥n de Benchmarks**: Identificar errores en anotaciones humanas

- ‚ùå **Producci√≥n en tiempo real**: Latencia cr√≠tica
- ‚ùå **Procesamiento masivo**: > 1000 documentos
- ‚ùå **Entornos con recursos limitados**: RAM < 8GB
- ‚ùå **Aplicaciones de usuario final**: Requieren respuesta instant√°nea
- ‚ùå **Exploraci√≥n general**: Cuando no se sabe qu√© entidades buscar
- ‚ùå **Descubrimiento autom√°tico**: Detecci√≥n de nuevas entidades no especificadas

#### **Estructura B√°sica del JSONL:**

```json
{
  "PMID": "12345",
  "Texto": "Texto del documento biom√©dico...",
  "Entidad": [
    {
      "texto": "nombre de enfermedad espec√≠fica",
      "tipo": "SpecificDisease"
    },
    {
      "texto": "otra entidad a buscar",
      "tipo": "SpecificDisease"
    }
  ]
}
```

#### **Ejemplo Pr√°ctico Completo:**

```json
{
  "PMID": "9876543",
  "Texto": "El paciente presenta s√≠ntomas de gripe con fiebre alta. Se le administr√≥ paracetamol 500mg cada 8 horas. Tambi√©n presenta dolor de cabeza y tos seca. El tratamiento incluye reposo y abundante l√≠quido.",
  "Entidad": [
    {
      "texto": "paracetamol",
      "tipo": "SpecificDisease"
    },
    {
      "texto": "gripe",
      "tipo": "SpecificDisease"
    }
  ]
}
```

#### **¬øQu√© Pasar√° con este Ejemplo?**

**‚úÖ Entidades que S√ç se detectar√°n:**
- "paracetamol" - porque est√° en la lista
- "gripe" - porque est√° en la lista

**‚ùå Entidades que NO se detectar√°n (aunque aparezcan en el texto):**
- "fiebre alta" - porque NO est√° en la lista
- "dolor de cabeza" - porque NO est√° en la lista
- "tos seca" - porque NO est√° en la lista
- "reposo" - porque NO est√° en la lista

**Resultado**: Solo extraer√°s informaci√≥n sobre pacientes que tomaron paracetamol y/o tuvieron gripe, no sobre otros s√≠ntomas o tratamientos.

#### **Reglas Importantes para el Campo "Entidad":**

1. **Entidad base**: Incluye la forma principal de la enfermedad que quieres detectar
2. **El LLM maneja variaciones**: No necesitas incluir todas las variaciones posibles. El sistema LLM detectar√° autom√°ticamente:
   - Sin√≥nimos m√©dicos
   - Abreviaturas comunes
   - Variaciones en nomenclatura
   - T√©rminos relacionados

3. **Ejemplo simplificado**: Solo necesitas incluir la entidad principal:
   ```json
   {
     "texto": "paracetamol",
     "tipo": "SpecificDisease"
   }
   ```
   
   **El sistema autom√°ticamente detectar√°:**
   - "paracetamol"
   - "acetaminof√©n" (nombre alternativo)
   - "Tylenol" (marca comercial)
   - Y otras variaciones relacionadas

**Nota**: El LLM es inteligente y encuentra variaciones autom√°ticamente. No es necesario ser exhaustivo en la lista de entidades.

#### **Ejemplo de Archivo JSONL Completo:**

```jsonl
{"PMID": "123", "Texto": "Texto del primer documento...", "Entidad": [{"texto": "enfermedad A", "tipo": "SpecificDisease"}]}
{"PMID": "124", "Texto": "Texto del segundo documento...", "Entidad": [{"texto": "enfermedad B", "tipo": "SpecificDisease"}, {"texto": "enfermedad C", "tipo": "SpecificDisease"}]}
{"PMID": "125", "Texto": "Texto del tercer documento...", "Entidad": []}
```

#### **Mejores Pr√°cticas para Preparar el JSONL:**

1. **Define entidades principales**: Incluye solo las enfermedades/entidades principales que quieres detectar
2. **Usa t√©rminos m√©dicos est√°ndar** cuando sea posible
3. **Mant√©n la lista simple**: No es necesario ser exhaustivo - el LLM es inteligente
4. **Prueba con un documento peque√±o** antes de procesar todo el dataset

#### **Herramientas Recomendadas para Preparar el JSONL:**

- **Anotadores manuales**: Para definir las entidades principales que quieres detectar
- **Scripts de preprocesamiento**: Para estandarizar el formato JSONL
- **Validaci√≥n simple**: Verificar que las entidades principales est√©n bien definidas
- **Documentaci√≥n**: Mantener una lista simple de entidades objetivo por proyecto

### Formato de Salida

```json
{
  "PMID": "12345",
  "Texto": "Texto original...",
  "Entidad": [
    {
      "texto": "entidad detectada",
      "tipo": "SpecificDisease",
      "confidence": 0.95,
      "strategies": ["regex", "llama32_balanced"]
    }
  ],
  "_multi_strategy": {
    "all_detections": {...},
    "entity_confidence": {...},
    "strategies_used": [...]
  }
}
```

## ü§ù Contribuci√≥n

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.

## üìû Soporte

Para preguntas o problemas:
- Abre un issue en GitHub
- Revisa la documentaci√≥n en `docs/`
- Consulta los logs de debug para informaci√≥n detallada

## üéØ Conclusiones y Recomendaciones

### **¬øCu√°ndo Usar Este Sistema?**

- **‚úÖ M√°xima Precisi√≥n**: Cuando la precisi√≥n > 95% es cr√≠tica
- **‚úÖ Investigaci√≥n**: Para validar y mejorar otros sistemas NER
- **‚úÖ Datasets Peque√±os**: < 5000 documentos para an√°lisis detallado
- **‚úÖ Prototipado**: Desarrollo de nuevas estrategias de NER
- **‚úÖ Correcci√≥n de Benchmarks**: Identificar errores en anotaciones humanas
- **‚úÖ Validaci√≥n de Calidad**: Verificar la calidad de datasets anotados

### **¬øCu√°ndo NO Usar Este Sistema?**

- **‚ùå Producci√≥n Masiva**: > 5000 documentos diarios
- **‚ùå Tiempo Real**: Aplicaciones que requieren < 1 segundo de respuesta
- **‚ùå Recursos Limitados**: Sistemas con < 8GB RAM
- **‚ùå Escalabilidad**: Entornos que requieren procesamiento paralelo masivo

### **Trade-off: Precisi√≥n vs Velocidad**

| Aspecto | BERT | NER Multi-Estrategia |
|---------|------|----------------------|
| **Precisi√≥n** | 90-95% | **95.4-99.7%** |
| **Velocidad** | **Muy R√°pido** | 20-60x m√°s lento |
| **Recursos** | **Bajo** | Alto |
| **Flexibilidad** | Baja | **Muy Alta** |
| **Interpretabilidad** | Baja | **Muy Alta** |
| **Correcci√≥n de Anotaciones** | No | **S√≠** |

**El sistema est√° dise√±ado para ser el mejor en precisi√≥n, no en velocidad.**

### **Pipeline de Optimizaci√≥n Recomendado**

1. **Dataset de Desarrollo**: Usar para optimizar temperatura, chunks y overlap
2. **Validaci√≥n Cruzada**: Probar diferentes configuraciones
3. **Test Final**: Evaluar con dataset de test optimizado
4. **Correcci√≥n de Benchmark**: Identificar y corregir errores en anotaciones
5. **M√©tricas Finales**: Reportar rendimiento con benchmark corregido

---

**Desarrollado para investigaci√≥n en NER biom√©dico con modelos de lenguaje local.**
