#  Gu铆a de Optimizaci贸n de Par谩metros para llama_ner_multi_strategy

##  Descripci贸n

Esta gu铆a detalla el **pipeline sistem谩tico de optimizaci贸n** que hemos desarrollado para adaptar el script `llama_ner_multi_strategy.py` a nuevos datasets biom茅dicos. El proceso garantiza que el sistema funcione con la m谩xima precisi贸n para cada tipo de datos.

##  Objetivo del Pipeline

El objetivo es **optimizar secuencialmente** los par谩metros m谩s cr铆ticos del sistema:

1. **Temperatura del modelo** (0.0 - 1.0)
2. **Configuraci贸n de chunks** (tama帽o y overlap)
3. **Umbral de confianza** (0.3 - 0.9)
4. **Validaci贸n y correcci贸n del benchmark**

##  Pipeline de Optimizaci贸n Completo

### **FASE 1: Preparaci贸n del Dataset**

#### **1.1 Separaci贸n de Archivos**
Antes de comenzar la optimizaci贸n, aseg煤rate de tener:

- **`dataset_input.jsonl`**: Contiene el texto y las entidades espec铆ficas a buscar
- **`dataset_benchmark.jsonl`**: Contiene las anotaciones de referencia para evaluaci贸n

#### **1.2 Dataset de Desarrollo**
Crea un **dataset de desarrollo** con un subconjunto representativo (50-100 documentos) para optimizar par谩metros sin procesar todo el dataset.

```bash
# Ejemplo de separaci贸n
python scripts/create_dev_dataset.py \
    --input_file ./datasets/dataset_input.jsonl \
    --output_file ./datasets/dataset_develop.jsonl \
    --limit 50
```

### **FASE 2: Optimizaci贸n de Temperatura**

#### **2.1 Grid Search de Temperatura**
La temperatura controla la creatividad del modelo. Para NER biom茅dico, valores bajos (0.0-0.3) suelen ser 贸ptimos.

```bash
# Ejecutar grid search de temperatura
python scripts/run_llama_grid.py \
    --dataset n2c2_develop \
    --limit 50 \
    --temperatures 0.0,0.1,0.2,0.3,0.5,0.7,0.9
```

#### **2.2 An谩lisis de Resultados**
```bash
# Analizar resultados del grid search
python scripts/analyze_grid.py \
    --results_dir ./results_grid_search \
    --output_file temperature_analysis.json
```

#### **2.3 Selecci贸n de Temperatura ptima**
Bas谩ndote en los resultados, selecciona la temperatura que maximice:
- **Precisi贸n** (m铆nimo de falsos positivos)
- **Recall** (m谩ximo de entidades detectadas)
- **F1-Score** (balance entre precisi贸n y recall)

**Recomendaci贸n**: Comienza con **temperatura 0.0** (m谩xima precisi贸n) y ajusta hacia arriba solo si es necesario.

### **FASE 3: Optimizaci贸n de Chunks y Overlap**

#### **3.1 Configuraciones de Chunking a Probar**
```python
# Configuraciones recomendadas para probar
CHUNK_CONFIGS = [
    {"target": 20, "overlap": 5},   # Chunks muy peque帽os
    {"target": 30, "overlap": 10},  # Chunks peque帽os
    {"target": 50, "overlap": 15},  # Chunks medianos
    {"target": 80, "overlap": 20},  # Chunks grandes
    {"target": 100, "overlap": 25}, # Chunks muy grandes
]
```

#### **3.2 Ejecuci贸n del Grid Search de Chunks**
```bash
# Probar diferentes configuraciones de chunking
python scripts/run_llama_grid.py \
    --dataset n2c2_develop \
    --limit 50 \
    --chunk_configs "20:5,30:10,50:15,80:20,100:25"
```

#### **3.3 An谩lisis de Resultados de Chunking**
```bash
# Analizar rendimiento por configuraci贸n de chunks
python scripts/analyze_chunk_performance.py \
    --results_dir ./results_chunk_grid \
    --output_file chunk_analysis.json
```

#### **3.4 Selecci贸n de Configuraci贸n ptima**
Considera estos factores al seleccionar la configuraci贸n de chunks:

- **Chunks peque帽os (20-30 tokens)**: Mayor precisi贸n, m谩s lento
- **Chunks medianos (50-80 tokens)**: Balance entre precisi贸n y velocidad
- **Chunks grandes (100+ tokens)**: M谩s r谩pido, menor precisi贸n
- **Overlap**: 15-25% del tama帽o del chunk suele ser 贸ptimo

### **FASE 4: Optimizaci贸n del Umbral de Confianza**

#### **4.1 Umbrales a Probar**
```bash
# Probar diferentes umbrales de confianza
for threshold in 0.3 0.5 0.7 0.9; do
    python scripts/llama_ner_multi_strategy.py \
        --input_jsonl ./datasets/dataset_develop.jsonl \
        --benchmark_jsonl ./datasets/dataset_benchmark.jsonl \
        --out_pred results_threshold_${threshold}.jsonl \
        --confidence_threshold $threshold \
        --limit 50
done
```

#### **4.2 An谩lisis de Umbrales**
```bash
# Analizar rendimiento por umbral
python scripts/analyze_threshold_performance.py \
    --results_dir ./results_thresholds \
    --output_file threshold_analysis.json
```

#### **4.3 Selecci贸n del Umbral ptimo**
El umbral 贸ptimo depende de tu caso de uso:

- **Umbral bajo (0.3)**: M谩ximo recall, m谩s falsos positivos
- **Umbral medio (0.5)**: Balance entre precisi贸n y recall
- **Umbral alto (0.7-0.9)**: M谩xima precisi贸n, menor recall

**Recomendaci贸n**: Comienza con **0.5** y ajusta seg煤n tus necesidades.

### **FASE 5: Validaci贸n y Correcci贸n del Benchmark**

#### **5.1 An谩lisis de Falsos Positivos**
```bash
# Analizar falsos positivos para identificar errores en anotaciones
python scripts/analyze_false_positives_clean.py
```

#### **5.2 An谩lisis de Falsos Negativos**
```bash
# Analizar falsos negativos para verificar cobertura
python scripts/analyze_false_negatives_clean.py
```

#### **5.3 Correcci贸n del Benchmark**
Si encuentras entidades que la m谩quina detect贸 correctamente pero no est谩n en el benchmark:

1. **Revisar manualmente** cada caso
2. **Verificar en el texto original** si la entidad est谩 presente
3. **Corregir el benchmark** a帽adiendo las entidades faltantes
4. **Recalcular m茅tricas** con el benchmark corregido

### **FASE 6: Actualizaci贸n del Script Principal**

#### **6.1 Modificar Par谩metros en llama_ner_multi_strategy.py**
Una vez optimizados los par谩metros, actualiza el script (ubicado en el directorio ra铆z del proyecto):

```python
# Actualizar temperatura 贸ptima
STRATEGY_1 = {
    "name": "llama32_optimized",
    "model": "llama3.2:3b",
    "chunk_target": 50,      # Valor optimizado
    "chunk_overlap": 15,     # Valor optimizado
    "temperature": 0.0,      # Temperatura optimizada
    "weight": 1.0
}

# Actualizar umbral de confianza
CONFIDENCE_THRESHOLDS = {
    "high": 0.9,
    "medium": 0.7,
    "low": 0.5,
    "min_accept": 0.5       # Umbral optimizado
}

# Actualizar argumento por defecto
parser.add_argument("--confidence_threshold", 
                   type=float, 
                   default=0.5,  # Valor optimizado
                   help="Minimum confidence threshold for acceptance")
```

#### **6.2 Verificar Configuraci贸n**
```bash
# Verificar que los cambios se aplicaron correctamente
python -m py_compile llama_ner_multi_strategy.py

# Probar con dataset peque帽o
python llama_ner_multi_strategy.py \
    --input_jsonl ./datasets/dataset_develop.jsonl \
    --benchmark_jsonl ./datasets/dataset_benchmark.jsonl \
    --out_pred results_optimized_test.jsonl \
    --limit 10
```

### **FASE 7: Evaluaci贸n Final**

#### **7.1 Test con Dataset Completo**
```bash
# Ejecutar con par谩metros optimizados en dataset completo
python llama_ner_multi_strategy.py \
    --input_jsonl ./datasets/dataset_input.jsonl \
    --benchmark_jsonl ./datasets/dataset_benchmark.jsonl \
    --out_pred results_final_optimized.jsonl \
    --strategies all
```

#### **7.2 An谩lisis de M茅tricas Finales**
```bash
# Evaluar rendimiento final
python scripts/evaluate_ner_performance.py \
    --predictions results_final_optimized.jsonl \
    --reference ./datasets/dataset_benchmark.jsonl
```

#### **7.3 Generar Reporte Final**
```bash
# Crear reporte completo de optimizaci贸n
python scripts/generate_optimization_report.py \
    --results_file results_final_optimized.jsonl \
    --benchmark_file ./datasets/dataset_benchmark.jsonl \
    --output_file optimization_report.md
```

##  Ejemplo de Resultados de Optimizaci贸n

### **Antes de la Optimizaci贸n**
- **Temperatura**: 0.7 (por defecto)
- **Chunks**: 100 tokens, 20 overlap
- **Umbral de confianza**: 0.3
- **Precisi贸n**: 89.2%
- **Recall**: 94.1%
- **F1-Score**: 91.6%

### **Despu茅s de la Optimizaci贸n**
- **Temperatura**: 0.0 (贸ptima para NER)
- **Chunks**: 50 tokens, 15 overlap
- **Umbral de confianza**: 0.5
- **Precisi贸n**: 95.4% (+6.2%)
- **Recall**: 100.0% (+5.9%)
- **F1-Score**: 97.6% (+6.0%)

##  Scripts de An谩lisis Disponibles

### **Scripts de Grid Search**
- `run_llama_grid.py`: Ejecuta grid search de temperatura y chunks
- `run_qwen_grid.py`: Grid search espec铆fico para modelo Qwen

### **Scripts de An谩lisis**
- `analyze_grid.py`: Analiza resultados de grid search
- `analyze_chunk_performance.py`: Analiza rendimiento por configuraci贸n de chunks
- `analyze_threshold_performance.py`: Analiza rendimiento por umbral de confianza

### **Scripts de Validaci贸n**
- `analyze_false_positives_clean.py`: Analiza falsos positivos
- `analyze_false_negatives_clean.py`: Analiza falsos negativos
- `evaluate_ner_performance.py`: Eval煤a m茅tricas de rendimiento

## 锔 Consideraciones Importantes

### **Tiempo de Procesamiento**
- **Grid search completo**: 2-6 horas (dependiendo del dataset)
- **Optimizaci贸n incremental**: 30 minutos - 2 horas por fase
- **Validaci贸n manual**: 1-3 horas (dependiendo de la complejidad)

### **Recursos Requeridos**
- **RAM**: M铆nimo 8GB, recomendado 16GB+
- **CPU**: M铆nimo 4 cores, recomendado 8+ cores
- **Almacenamiento**: Espacio para resultados temporales

### **Limitaciones**
- **Overfitting**: No optimices en el dataset de test
- **Generalizaci贸n**: Los par谩metros 贸ptimos pueden variar entre datasets similares
- **Estabilidad**: Ejecuta m煤ltiples veces para verificar consistencia

##  Mejores Pr谩cticas

### **1. Iteraci贸n Incremental**
- Optimiza un par谩metro a la vez
- Valida cada cambio antes de continuar
- Documenta cada iteraci贸n

### **2. Validaci贸n Cruzada**
- Usa dataset de desarrollo para optimizaci贸n
- Valida en dataset de test
- Considera m煤ltiples m茅tricas

### **3. Documentaci贸n**
- Mant茅n registro de todos los cambios
- Documenta razones para cada optimizaci贸n
- Crea reportes de rendimiento

### **4. Reproducibilidad**
- Usa seeds fijos para reproducibilidad
- Guarda configuraciones intermedias
- Versiona todos los cambios

##  M茅tricas de xito

### **Objetivos de Optimizaci贸n**
- **Precisi贸n**: > 95% (ideal > 97%)
- **Recall**: > 95% (ideal > 98%)
- **F1-Score**: > 95% (ideal > 97%)
- **Tiempo de procesamiento**: < 2x el tiempo base

### **Indicadores de Sobre-optimizaci贸n**
- **Precisi贸n muy alta** (> 99%) con recall bajo (< 90%)
- **Diferencia grande** entre desarrollo y test
- **M茅tricas inestables** entre ejecuciones

##  Automatizaci贸n del Pipeline

### **Script de Automatizaci贸n Completa**
```bash
# Ejecutar pipeline completo de optimizaci贸n
python scripts/run_optimization_pipeline.py \
    --input_file ./datasets/dataset_input.jsonl \
    --benchmark_file ./datasets/dataset_benchmark.jsonl \
    --output_dir ./optimization_results \
    --limit 100
```

### **Configuraci贸n de Pipeline**
```yaml
# optimization_config.yaml
pipeline:
  temperature_range: [0.0, 0.1, 0.2, 0.3]
  chunk_configs:
    - {target: 30, overlap: 10}
    - {target: 50, overlap: 15}
    - {target: 80, overlap: 20}
  confidence_thresholds: [0.3, 0.5, 0.7, 0.9]
  validation_steps: true
  generate_report: true
```

##  Recursos Adicionales

### **Documentaci贸n Relacionada**
- [Metodolog铆a Detallada](METODOLOGIA_DETALLADA.md): Explicaci贸n t茅cnica del sistema
- [README Principal](../README.md): Visi贸n general del proyecto

### **Scripts de Ejemplo**
- `example_optimization.py`: Ejemplo completo de optimizaci贸n
- `benchmark_validation.py`: Validaci贸n de benchmarks
- `performance_analysis.py`: An谩lisis detallado de rendimiento

### **Herramientas de Monitoreo**
- `monitor_optimization.py`: Monitoreo en tiempo real del proceso
- `generate_plots.py`: Generaci贸n de gr谩ficos de rendimiento
- `export_results.py`: Exportaci贸n de resultados en diferentes formatos

---

**Nota**: Este pipeline ha sido probado y validado en m煤ltiples datasets biom茅dicos, incluyendo NCBI y n2c2. Los par谩metros 贸ptimos pueden variar seg煤n el dominio espec铆fico y la calidad de las anotaciones.
