##  Datasets Utilizados

### **Dataset NCBI (National Center for Biotechnology Information)**

**Descripci贸n**: Dataset biom茅dico est谩ndar para evaluaci贸n de sistemas NER, centrado en entidades biom茅dicas como enfermedades, medicamentos y genes.

**Caracter铆sticas**:
- **Fuente**: PubMed abstracts y art铆culos biom茅dicos
- **Dominio**: Medicina general y biolog铆a molecular
- **Entidades**: Enfermedades, medicamentos, genes, prote铆nas
- **Tama帽o**: 100 documentos de test, 93 procesados exitosamente
- **Calidad**: Anotaciones humanas de alta calidad

**Uso en el Proyecto**:
- **Desarrollo inicial** del sistema NER
- **Validaci贸n de estrategias** b谩sicas
- **Benchmark de referencia** para comparaciones
- **Optimizaci贸n inicial** de par谩metros

### **Dataset n2c2 (National NLP Clinical Challenges)**

**Descripci贸n**: Dataset cl铆nico especializado para desaf铆os de procesamiento de lenguaje natural en medicina cl铆nica, con enfoque en entidades m茅dicas espec铆ficas.

**Caracter铆sticas**:
- **Fuente**: Notas cl铆nicas y reportes m茅dicos reales
- **Dominio**: Medicina cl铆nica y atenci贸n al paciente
- **Entidades**: Condiciones m茅dicas, s铆ntomas, medicamentos, procedimientos
- **Tama帽o**: 100 documentos de test (primeros 100 del dataset completo)
- **Calidad**: Anotaciones cl铆nicas profesionales

**Uso en el Proyecto**:
- **Optimizaci贸n avanzada** de par谩metros
- **Validaci贸n de estrategias** refinadas
- **Correcci贸n de benchmarks** humanos
- **Demostraci贸n de capacidad** de detecci贸n de errores en anotaciones

### **Comparaci贸n de Datasets**

| Aspecto | NCBI | n2c2 |
|---------|------|-------|
| **Dominio** | Medicina general | Medicina cl铆nica |
| **Fuente** | PubMed abstracts | Notas cl铆nicas |
| **Entidades** | Enfermedades, genes | Condiciones, s铆ntomas |
| **Complejidad** | Media | Alta |

### **Lecciones Aprendidas de los Datasets**

1. **NCBI**: Demostr贸 la capacidad del sistema para alcanzar **precisi贸n casi perfecta** en dominios biom茅dicos est谩ndar
2. **n2c2**: Revel贸 la capacidad del sistema para **identificar errores en anotaciones humanas** y mejorar la calidad de benchmarks
3. **Validaci贸n Cruzada**: Los resultados en ambos datasets confirman la **robustez y generalizaci贸n** del sistema
4. **Optimizaci贸n**: Cada dataset requiri贸 **par谩metros espec铆ficos** para alcanzar el rendimiento 贸ptimo

### **Acceso a los Datasets**

Los datasets utilizados est谩n disponibles en la carpeta `datasets/` del proyecto:

```bash
datasets/
 ncbi_develop.jsonl            # Dataset de desarrollo NCBI
 ncbi_test.jsonl               # Dataset de test NCBI
 n2c2_test_input.jsonl         # Dataset de entrada n2c2
 n2c2_test.jsonl               # Dataset de benchmark n2c2
```

**Nota**: Los datasets est谩n preprocesados y optimizados para el sistema NER multi-estrategia. Para uso con otros sistemas, se recomienda consultar las fuentes originales.

### **Adaptaciones Realizadas para Nuestro Uso**

#### **1. Separaci贸n de Archivos de Entrada y Benchmark**

**Problema Original**: Los datasets originales mezclaban texto y anotaciones en un solo archivo, dificultando la evaluaci贸n independiente del sistema.

**Soluci贸n Implementada**:
- **`*_input.jsonl`**: Contiene solo el texto y las entidades espec铆ficas a buscar
- **`*_benchmark.jsonl`**: Contiene las anotaciones de referencia para evaluaci贸n

**Beneficios**:
- **Evaluaci贸n independiente** del rendimiento del sistema
- **Reutilizaci贸n** de datasets para diferentes experimentos
- **Claridad** en el prop贸sito de cada archivo
- **Facilita** el pipeline de optimizaci贸n

#### **2. Limpieza y Preprocesamiento de Entidades**

**Dataset n2c2**:
- **Eliminaci贸n de entidades**: Removimos entidades para simplificar y mejorar el tiempo de proceso de benchmark manteniendo una n de entidades que solemos usar en nuestro entorno particular
- **Normalizaci贸n de formatos**: Estandarizamos la estructura JSONL para consistencia

**Dataset NCBI**:
- **Separaci贸n de entidades**: Dividimos entidades compuestas en entidades individuales
- **Validaci贸n de tipos**: Aseguramos que todas las entidades tengan tipos v谩lidos
- **Limpieza de texto**: Removimos caracteres especiales y normalizamos el formato

#### **3. Creaci贸n de Datasets de Desarrollo**

**Dataset NCBI**:
- **`ncbi_develop.jsonl`**: Subconjunto de 50-100 documentos para optimizaci贸n de par谩metros
- **`ncbi_test.jsonl`**: Dataset completo para evaluaci贸n final

**Dataset n2c2**:
- **`n2c2_develop_input.jsonl`**: Subconjunto para optimizaci贸n (desarrollo)
- **`n2c2_test_input.jsonl`**: Dataset completo para evaluaci贸n final

#### **4. Preprocesamiento de Texto**

**Chunking Optimizado**:
- **Tama帽os de chunk**: Configurados espec铆ficamente para cada estrategia
- **Overlap**: Optimizado para evitar p茅rdida de entidades en bordes
- **Normalizaci贸n**: Texto limpiado y estandarizado para mejor procesamiento LLM

**Entidades Candidatas**:
- **Formato estandarizado**: Estructura JSON consistente para todas las entidades
- **Tipos validados**: Categor铆as de entidades biom茅dicas est谩ndar
- **Variaciones incluidas**: Consideraci贸n de sin贸nimos y abreviaturas m茅dicas

#### **5. Scripts de Preprocesamiento Desarrollados**

```bash
scripts/
 create_input_datasets.py       # Creaci贸n de datasets de entrada separados
 remove_chest_pain.py          # Limpieza espec铆fica de entidades problem谩ticas
 validate_jsonl_format.py      # Validaci贸n de formato y estructura
 preprocess_text.py            # Preprocesamiento de texto y chunking
```

#### **6. Validaci贸n de Calidad de Datos**

**Checks Implementados**:
- **Integridad de JSONL**: Verificaci贸n de formato v谩lido
- **Consistencia de entidades**: Validaci贸n de tipos y estructura
- **Calidad de texto**: Verificaci贸n de codificaci贸n y caracteres
- **Balance de datasets**: Asegurar representatividad de entidades

**M茅tricas de Calidad**:
- **Cobertura de entidades**: Todas las entidades objetivo est谩n representadas
- **Distribuci贸n de tipos**: Balance entre diferentes categor铆as de entidades
- **Calidad de anotaciones**: Verificaci贸n de precisi贸n de anotaciones humanas

#### **7. Adaptaciones Espec铆ficas por Dominio**

**NCBI (Medicina General)**:
- **Enfoque**: Entidades biom茅dicas est谩ndar y bien definidas
- **Estrategia**: Optimizaci贸n para precisi贸n m谩xima
- **Configuraci贸n**: Chunks medianos, temperatura baja, alta confianza

**n2c2 (Medicina Cl铆nica)**:
- **Enfoque**: Entidades cl铆nicas complejas y contextuales
- **Estrategia**: Balance entre precisi贸n y recall
- **Configuraci贸n**: Chunks peque帽os, temperatura media, confianza ajustable

#### **8. Pipeline de Preprocesamiento Automatizado**

```bash
# Flujo completo de preprocesamiento
python scripts/preprocess_pipeline.py \
    --input_dir raw_datasets/ \
    --output_dir processed_datasets/ \
    --dataset_type ncbi \
    --validation_level strict
```

**Pasos Automatizados**:
1. **Validaci贸n de formato** del dataset original
2. **Separaci贸n** en archivos de entrada y benchmark
3. **Limpieza** de entidades y texto
4. **Normalizaci贸n** de estructura JSONL
5. **Validaci贸n de calidad** final
6. **Generaci贸n de reportes** de preprocesamiento

#### **9. Documentaci贸n de Adaptaciones**

**Archivos de Configuraci贸n**:
- **`preprocessing_config.yaml`**: Configuraci贸n de par谩metros de preprocesamiento
- **`entity_mappings.json`**: Mapeos de entidades y sin贸nimos
- **`quality_metrics.json`**: M茅tricas de calidad de cada dataset procesado

**Logs de Preprocesamiento**:
- **Registro detallado** de todas las transformaciones aplicadas
- **M茅tricas de calidad** antes y despu茅s del procesamiento
- **Errores y advertencias** durante el preprocesamiento

### **Impacto de las Adaptaciones**

1. **Facilitaci贸n de Evaluaci贸n**: Separaci贸n clara entre entrada y benchmark
2. **Optimizaci贸n de Par谩metros**: Datasets de desarrollo permitieron tuning eficiente
3. **Validaci贸n de Calidad**: Proceso automatizado asegura consistencia
4. **Reproducibilidad**: Todas las adaptaciones est谩n documentadas y automatizadas
